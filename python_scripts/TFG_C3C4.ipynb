{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'shape' from 'C:\\\\Users\\\\USER\\\\Documents\\\\Yachay_Tech\\\\Thesis_Project\\\\ParkinsonsDetection\\\\python_scripts\\\\shape.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyQt5\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib qt5\n",
    "\n",
    "#python packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pac\n",
    "import warnings\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "import imp\n",
    "import shape\n",
    "import utils\n",
    "from load_features import load_WaveformShape_features, Bandpower_features, mean_and_peak_freqs, statistics, fractal_dimensions, entropies\n",
    "from val_metrics import *\n",
    "\n",
    "imp.reload(utils)\n",
    "imp.reload(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Which comparison to make:\n",
    "    1. Off-med vs Controls\n",
    "    2. On-med vs Controls\n",
    "    3. Off-med vs On-med\n",
    "    \"\"\"\n",
    "comparison = 3\n",
    "dataset = 'UCSD' #UCSD or UNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data and meta-data\n",
    "all_chan = False; EO = False\n",
    "bands = [[0.5,4], [4,8], [8,12], [16,32], [32,64]] #Delta, Theta, Alpha, Beta, Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs, t, S, Sc, Smed, flo, fhi = utils.loadmeta()  \n",
    "eeg,rejects = utils.loadPD(EO, all_chan, dataset) # EO means Eyes Opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a signal\n",
    "sns.set(font_scale=1.2)\n",
    "data = eeg['C'][1]\n",
    "time = np.arange(data.size) / Fs\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.plot(time, data, lw=1.5, color='k')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.xlim([time.min(), time.max()])\n",
    "plt.title('EEG Signal for Healthy Subject')\n",
    "sns.despine()\n",
    "\n",
    "# plt.plot(eeg['off'][6,0:1000],label='control')\n",
    "# plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform Shape Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell saves features from waveform shape and PAC in .pkl files -- Just run once, then commented--\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell saves features from waveform shape and PAC in .pkl files -- Just run once, then commented--\n",
    "\"\"\"\n",
    "# import pickle\n",
    "# shape_features = [ShR, PTR, StR, RDR, pac]\n",
    "# shape_featuresStr = [\"ShR\", \"PTR\", \"StR\", \"RDR\", \"pac\"]\n",
    "# for i in range(len(shape_features)):\n",
    "#     f = open(shape_featuresStr[i] + \".pkl\",\"wb\")\n",
    "#     pickle.dump(shape_features[i],f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function calculates the shape measures calculated for analysis\n",
    "    of the PD data set\n",
    "\n",
    "    1. Peak and trough times(pks,trs)\n",
    "    2. Peak and trough sharpness(pksharp,trsharp)\n",
    "    3. Rise and decay steepnes(risteep,desteep)\n",
    "    3. Sharpness ratio(ShR)\n",
    "    4. Steepness ratio(StR)\n",
    "    5. Peak-to-trough ratio(PTR)\n",
    "    6. Rise-to-decay ratio(RDR)\n",
    "    \"\"\"\n",
    "widthS = 3 #To calculate Waveform Shape features\n",
    "\n",
    "pks,trs,ShR,PTR,StR,RDR = utils.measure_shape(eeg, rejects, widthS=widthS)\n",
    "\"\"\"\n",
    "Algorithms for estimating phase-amplitude coupling\n",
    "\"\"\"\n",
    "pac = utils.measure_pac(eeg,rejects,flo,fhi,Fs=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Spectral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Absolute and Relative BandPower features, from all five bands: Delta, Theta, Alpha, Beta, Gamma\n",
    "\"\"\"\n",
    "abs_powerOff = Bandpower_features(eeg['off'], Fs, bands, S, False, 'welch')\n",
    "abs_powerOn = Bandpower_features(eeg['on'], Fs, bands, Smed, False, 'welch')\n",
    "abs_powerCtl = Bandpower_features(eeg['C'], Fs, bands, Sc, False, 'welch')\n",
    "\n",
    "rel_powerOff = Bandpower_features(eeg['off'], Fs, bands, S, True, 'welch')\n",
    "rel_powerOn = Bandpower_features(eeg['on'], Fs, bands, Smed, True, 'welch')\n",
    "rel_powerCtl = Bandpower_features(eeg['C'], Fs, bands, Sc, True, 'welch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mean and Peak Frequency from the spectrum\n",
    "\"\"\"\n",
    "meanFreqsOff = mean_and_peak_freqs(eeg['off'], Fs, S)[0] \n",
    "meanFreqsOn = mean_and_peak_freqs(eeg['on'], Fs, Smed)[0]\n",
    "meanFreqsCtl = mean_and_peak_freqs(eeg['C'], Fs, Sc)[0]\n",
    "\n",
    "peakFreqsOff = mean_and_peak_freqs(eeg['off'], Fs, S)[1]\n",
    "peakFreqsOn = mean_and_peak_freqs(eeg['on'], Fs, Smed)[1]\n",
    "peakFreqsCtl = mean_and_peak_freqs(eeg['C'], Fs, Sc)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell calculates statistical measures extracted from EEG for analysis\n",
    "    of the PD data set\n",
    "\n",
    "    1. Mean\n",
    "    2. Standard Deviation\n",
    "    3. Skewness\n",
    "    4. Kurtosis\n",
    "    5. Maximum\n",
    "    6. Minimum\n",
    "    7. 5th percentile value\n",
    "    8. 25th percentile value\n",
    "    9. 75th percentile value\n",
    "    10. 95th percentile value\n",
    "    11. Median\n",
    "    12. Variance\n",
    "    13. Root Mean Square value\n",
    "    \"\"\"\n",
    "statsOff = statistics(eeg['off'], S).get()\n",
    "statsOn = statistics(eeg['on'], Smed).get()\n",
    "statsCtl = statistics(eeg['C'], Sc).get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractalOff = fractal_dimensions(eeg['off'], S)\n",
    "fractalOn = fractal_dimensions(eeg['on'], Smed)\n",
    "fractalCtl = fractal_dimensions(eeg['C'], Sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "entOff = entropies(eeg['off'], S, Fs)\n",
    "entOn = entropies(eeg['on'], Smed, Fs)\n",
    "entCtl = entropies(eeg['C'], Sc, Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class I\n",
    "f1_B    = np.reshape(pac['off'],(S,1))\n",
    "f2_B    = np.reshape(ShR['off'],(S,1))\n",
    "f3_B    = np.reshape(StR['off'],(S,1))\n",
    "f4_B    = np.reshape(PTR['off'],(S,1))\n",
    "f5_B    = np.reshape(RDR['off'],(S,1))\n",
    "cl_B    = np.ones((S,1)) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class II\n",
    "f1_C    = np.reshape(pac['on'],(Smed,1))\n",
    "f2_C    = np.reshape(ShR['on'],(Smed,1))\n",
    "f3_C    = np.reshape(StR['on'],(Smed,1))\n",
    "f4_C    = np.reshape(PTR['on'],(Smed,1))\n",
    "f5_C    = np.reshape(RDR['on'],(Smed,1))\n",
    "if comparison == 1 or comparison == 3:\n",
    "    cl_C    = np.zeros((Smed,1)) # transition means 0 #Original line\n",
    "elif comparison == 2:\n",
    "    cl_C    = np.ones((Smed,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class III\n",
    "f1_E    = np.reshape(pac['C'],(Sc,1))\n",
    "f2_E    = np.reshape(ShR['C'],(Sc,1))\n",
    "f3_E    = np.reshape(StR['C'],(Sc,1))\n",
    "f4_E    = np.reshape(PTR['C'],(Sc,1))\n",
    "f5_E    = np.reshape(RDR['C'],(Sc,1))\n",
    "cl_E    = np.negative(np.ones((Sc,1))) # -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MftB = np.concatenate([f1_B,f2_B,f3_B, f4_B, f5_B, rel_powerOff, abs_powerOff, meanFreqsOff, peakFreqsOff, statsOff, fractalOff, entOff, cl_B],axis=1)\n",
    "MftC = np.concatenate([f1_C,f2_C,f3_C, f4_C, f5_C, rel_powerOn,  abs_powerOn,  meanFreqsOn, peakFreqsOn,   statsOn,  fractalOn, entOn,  cl_C],axis=1)\n",
    "MftE = np.concatenate([f1_E,f2_E,f3_E, f4_E, f5_E, rel_powerCtl, abs_powerCtl, meanFreqsCtl, peakFreqsCtl, statsCtl, fractalCtl, entCtl, cl_E],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['PAC','ShR','StR', 'PtT', 'RtF', 'rel_delta',\n",
    "            'rel_theta','rel_alpha','rel_beta',\n",
    "            'rel_gamma','abs_delta','abs_theta',\n",
    "            'abs_alpha','abs_beta','abs_gamma','meanFreq','peakFreq',\n",
    "            'mean','std','skewness', 'kurtosis', 'maximum', 'minimum',\n",
    "            '5th perc','25th perc','75th perc','95th perc','median','variance','RMS',\n",
    "           'detrended_fluctuation', 'higuchi_fd', 'katz_fd', 'petrosian_fd',\n",
    "           'perm_entropy', 'svd_entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCM_B = pd.DataFrame(MftB,columns= features + ['class'])\n",
    "FCM_C = pd.DataFrame(MftC,columns= features + ['class'])\n",
    "FCM_E = pd.DataFrame(MftE,columns= features + ['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification between patients on-medication and patients off-medication   \n",
    "\n",
    "if comparison == 3:\n",
    "    TotalDataset = pd.concat([FCM_B,FCM_C],ignore_index=True)\n",
    "    visDat = TotalDataset.copy(deep=True)\n",
    "    visDat['class'] = visDat['class'].map({1:'off_med',0:'on_med'})\n",
    "\n",
    "#Classification between patients on-medication and healthy control subjects        \n",
    "\n",
    "elif comparison == 2:\n",
    "    TotalDataset = pd.concat([FCM_C,FCM_E],ignore_index=True)\n",
    "    visDat = TotalDataset.copy(deep=True)\n",
    "    # visDat['class'] = visDat['class'].map({-1:'control',0:'on_med'}) #Original line\n",
    "    visDat['class'] = visDat['class'].map({-1:'control',1:'on_med'})\n",
    "\n",
    "#Classification between patients off-medication and healthy control subjects        \n",
    "\n",
    "elif comparison == 1:\n",
    "    TotalDataset = pd.concat([FCM_E,FCM_B],ignore_index=True)\n",
    "    visDat = TotalDataset.copy(deep=True)\n",
    "    visDat['class'] = visDat['class'].map({-1:'control',1:'off_med'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAC</th>\n",
       "      <th>ShR</th>\n",
       "      <th>StR</th>\n",
       "      <th>PtT</th>\n",
       "      <th>RtF</th>\n",
       "      <th>rel_delta</th>\n",
       "      <th>rel_theta</th>\n",
       "      <th>rel_alpha</th>\n",
       "      <th>rel_beta</th>\n",
       "      <th>rel_gamma</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>variance</th>\n",
       "      <th>RMS</th>\n",
       "      <th>detrended_fluctuation</th>\n",
       "      <th>higuchi_fd</th>\n",
       "      <th>katz_fd</th>\n",
       "      <th>petrosian_fd</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017733</td>\n",
       "      <td>0.098913</td>\n",
       "      <td>0.163642</td>\n",
       "      <td>1.255779</td>\n",
       "      <td>0.686054</td>\n",
       "      <td>0.136813</td>\n",
       "      <td>0.072965</td>\n",
       "      <td>0.159242</td>\n",
       "      <td>0.296707</td>\n",
       "      <td>0.148003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145518</td>\n",
       "      <td>14.431695</td>\n",
       "      <td>2.983523</td>\n",
       "      <td>0.971172</td>\n",
       "      <td>1.538859</td>\n",
       "      <td>3.156071</td>\n",
       "      <td>1.017937</td>\n",
       "      <td>2.312534</td>\n",
       "      <td>1.173157</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015171</td>\n",
       "      <td>0.027426</td>\n",
       "      <td>0.034887</td>\n",
       "      <td>0.938801</td>\n",
       "      <td>0.922812</td>\n",
       "      <td>0.144274</td>\n",
       "      <td>0.306474</td>\n",
       "      <td>0.197352</td>\n",
       "      <td>0.221095</td>\n",
       "      <td>0.172563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175242</td>\n",
       "      <td>12.177666</td>\n",
       "      <td>2.757860</td>\n",
       "      <td>1.124485</td>\n",
       "      <td>1.472822</td>\n",
       "      <td>2.393348</td>\n",
       "      <td>1.017533</td>\n",
       "      <td>2.318673</td>\n",
       "      <td>0.968671</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074130</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.180660</td>\n",
       "      <td>0.872361</td>\n",
       "      <td>0.659689</td>\n",
       "      <td>0.255378</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0.112770</td>\n",
       "      <td>0.184038</td>\n",
       "      <td>0.273906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184774</td>\n",
       "      <td>4.240290</td>\n",
       "      <td>1.602635</td>\n",
       "      <td>0.912102</td>\n",
       "      <td>1.667425</td>\n",
       "      <td>3.347637</td>\n",
       "      <td>1.018317</td>\n",
       "      <td>2.329433</td>\n",
       "      <td>1.272294</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.079251</td>\n",
       "      <td>0.181069</td>\n",
       "      <td>1.200192</td>\n",
       "      <td>0.659069</td>\n",
       "      <td>0.080871</td>\n",
       "      <td>0.084503</td>\n",
       "      <td>0.151343</td>\n",
       "      <td>0.163961</td>\n",
       "      <td>0.199832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249745</td>\n",
       "      <td>12.298036</td>\n",
       "      <td>2.791133</td>\n",
       "      <td>0.815680</td>\n",
       "      <td>1.759567</td>\n",
       "      <td>4.118678</td>\n",
       "      <td>1.019734</td>\n",
       "      <td>2.417424</td>\n",
       "      <td>1.377425</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.050979</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>1.124550</td>\n",
       "      <td>1.014498</td>\n",
       "      <td>0.064976</td>\n",
       "      <td>0.182431</td>\n",
       "      <td>0.240476</td>\n",
       "      <td>0.205108</td>\n",
       "      <td>0.181574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108688</td>\n",
       "      <td>8.402344</td>\n",
       "      <td>2.283840</td>\n",
       "      <td>1.018992</td>\n",
       "      <td>1.515206</td>\n",
       "      <td>3.096279</td>\n",
       "      <td>1.017425</td>\n",
       "      <td>2.305711</td>\n",
       "      <td>1.066772</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>0.019738</td>\n",
       "      <td>0.074054</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.843230</td>\n",
       "      <td>1.033747</td>\n",
       "      <td>0.106573</td>\n",
       "      <td>0.260207</td>\n",
       "      <td>0.276501</td>\n",
       "      <td>0.199614</td>\n",
       "      <td>0.120696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059966</td>\n",
       "      <td>6.710670</td>\n",
       "      <td>2.081394</td>\n",
       "      <td>1.126202</td>\n",
       "      <td>1.359608</td>\n",
       "      <td>2.451823</td>\n",
       "      <td>1.016800</td>\n",
       "      <td>2.287053</td>\n",
       "      <td>0.885987</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.031093</td>\n",
       "      <td>0.052324</td>\n",
       "      <td>1.074220</td>\n",
       "      <td>1.128039</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>0.111056</td>\n",
       "      <td>0.081581</td>\n",
       "      <td>0.265683</td>\n",
       "      <td>0.372943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003529</td>\n",
       "      <td>6.073371</td>\n",
       "      <td>1.964574</td>\n",
       "      <td>0.980170</td>\n",
       "      <td>1.681824</td>\n",
       "      <td>3.713433</td>\n",
       "      <td>1.013435</td>\n",
       "      <td>2.131549</td>\n",
       "      <td>1.104992</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.046552</td>\n",
       "      <td>1.021585</td>\n",
       "      <td>0.898356</td>\n",
       "      <td>0.111009</td>\n",
       "      <td>0.196301</td>\n",
       "      <td>0.274965</td>\n",
       "      <td>0.217806</td>\n",
       "      <td>0.137826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056445</td>\n",
       "      <td>8.597344</td>\n",
       "      <td>2.331193</td>\n",
       "      <td>1.081778</td>\n",
       "      <td>1.372105</td>\n",
       "      <td>2.855682</td>\n",
       "      <td>1.015550</td>\n",
       "      <td>2.234730</td>\n",
       "      <td>0.918034</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.011085</td>\n",
       "      <td>0.023967</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>1.056737</td>\n",
       "      <td>1.063928</td>\n",
       "      <td>0.144146</td>\n",
       "      <td>0.208713</td>\n",
       "      <td>0.203343</td>\n",
       "      <td>0.242096</td>\n",
       "      <td>0.131568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>8.454064</td>\n",
       "      <td>2.358044</td>\n",
       "      <td>1.026892</td>\n",
       "      <td>1.375314</td>\n",
       "      <td>2.879516</td>\n",
       "      <td>1.015037</td>\n",
       "      <td>2.240442</td>\n",
       "      <td>0.945589</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0.029532</td>\n",
       "      <td>0.031439</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>1.075077</td>\n",
       "      <td>1.063379</td>\n",
       "      <td>0.271474</td>\n",
       "      <td>0.152798</td>\n",
       "      <td>0.106016</td>\n",
       "      <td>0.185974</td>\n",
       "      <td>0.332604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107931</td>\n",
       "      <td>4.988533</td>\n",
       "      <td>1.797578</td>\n",
       "      <td>1.009086</td>\n",
       "      <td>1.709970</td>\n",
       "      <td>3.143799</td>\n",
       "      <td>1.016764</td>\n",
       "      <td>2.277987</td>\n",
       "      <td>1.180922</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PAC       ShR       StR       PtT       RtF  rel_delta  rel_theta  \\\n",
       "0     0.017733  0.098913  0.163642  1.255779  0.686054   0.136813   0.072965   \n",
       "1     0.015171  0.027426  0.034887  0.938801  0.922812   0.144274   0.306474   \n",
       "2     0.074130  0.059304  0.180660  0.872361  0.659689   0.255378   0.102832   \n",
       "3     0.040598  0.079251  0.181069  1.200192  0.659069   0.080871   0.084503   \n",
       "4     0.024312  0.050979  0.006251  1.124550  1.014498   0.064976   0.182431   \n",
       "...        ...       ...       ...       ...       ...        ...        ...   \n",
       "1075  0.019738  0.074054  0.014414  0.843230  1.033747   0.106573   0.260207   \n",
       "1076  0.002907  0.031093  0.052324  1.074220  1.128039   0.226736   0.111056   \n",
       "1077  0.011754  0.009274  0.046552  1.021585  0.898356   0.111009   0.196301   \n",
       "1078  0.011085  0.023967  0.026912  1.056737  1.063928   0.144146   0.208713   \n",
       "1079  0.029532  0.031439  0.026688  1.075077  1.063379   0.271474   0.152798   \n",
       "\n",
       "      rel_alpha  rel_beta  rel_gamma  ...    median   variance       RMS  \\\n",
       "0      0.159242  0.296707   0.148003  ...  0.145518  14.431695  2.983523   \n",
       "1      0.197352  0.221095   0.172563  ... -0.175242  12.177666  2.757860   \n",
       "2      0.112770  0.184038   0.273906  ...  0.184774   4.240290  1.602635   \n",
       "3      0.151343  0.163961   0.199832  ... -0.249745  12.298036  2.791133   \n",
       "4      0.240476  0.205108   0.181574  ...  0.108688   8.402344  2.283840   \n",
       "...         ...       ...        ...  ...       ...        ...       ...   \n",
       "1075   0.276501  0.199614   0.120696  ...  0.059966   6.710670  2.081394   \n",
       "1076   0.081581  0.265683   0.372943  ... -0.003529   6.073371  1.964574   \n",
       "1077   0.274965  0.217806   0.137826  ...  0.056445   8.597344  2.331193   \n",
       "1078   0.203343  0.242096   0.131568  ...  0.203333   8.454064  2.358044   \n",
       "1079   0.106016  0.185974   0.332604  ... -0.107931   4.988533  1.797578   \n",
       "\n",
       "      detrended_fluctuation  higuchi_fd   katz_fd  petrosian_fd  perm_entropy  \\\n",
       "0                  0.971172    1.538859  3.156071      1.017937      2.312534   \n",
       "1                  1.124485    1.472822  2.393348      1.017533      2.318673   \n",
       "2                  0.912102    1.667425  3.347637      1.018317      2.329433   \n",
       "3                  0.815680    1.759567  4.118678      1.019734      2.417424   \n",
       "4                  1.018992    1.515206  3.096279      1.017425      2.305711   \n",
       "...                     ...         ...       ...           ...           ...   \n",
       "1075               1.126202    1.359608  2.451823      1.016800      2.287053   \n",
       "1076               0.980170    1.681824  3.713433      1.013435      2.131549   \n",
       "1077               1.081778    1.372105  2.855682      1.015550      2.234730   \n",
       "1078               1.026892    1.375314  2.879516      1.015037      2.240442   \n",
       "1079               1.009086    1.709970  3.143799      1.016764      2.277987   \n",
       "\n",
       "      svd_entropy    class  \n",
       "0        1.173157  off_med  \n",
       "1        0.968671  off_med  \n",
       "2        1.272294  off_med  \n",
       "3        1.377425  off_med  \n",
       "4        1.066772  off_med  \n",
       "...           ...      ...  \n",
       "1075     0.885987   on_med  \n",
       "1076     1.104992   on_med  \n",
       "1077     0.918034   on_med  \n",
       "1078     0.945589   on_med  \n",
       "1079     1.180922   on_med  \n",
       "\n",
       "[1080 rows x 37 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visDat.head(3240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = np.arange(17,25)\n",
    "off = FCM_B.iloc[:,interval].mean(axis=0)\n",
    "on = FCM_C.iloc[:,interval].mean(axis=0)\n",
    "control = FCM_E.iloc[:,interval].mean(axis=0)\n",
    "\n",
    "df = pd.DataFrame({'PD Off-medication': off,\n",
    "                   'PD On-medication': on,\n",
    "                   'Healthy': control}, index=np.asarray(features)[interval])\n",
    "ax = df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TotalDataset[features]\n",
    "y = TotalDataset[['class']]\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn import datasets\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # load dataset\n",
    "# df = pd.DataFrame(X, columns=features)\n",
    "\n",
    "# # Standarize Data\n",
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(df)\n",
    "# data_scaled = pd.DataFrame(scaler.transform(df),columns = df.columns) \n",
    "\n",
    "# # PCA\n",
    "# pca = PCA(.95)\n",
    "# # pca.fit_transform(data_scaled)\n",
    "# X = pca.fit_transform(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get component loadings (correlation coefficient between original variables and the component) \n",
    "# # the squared loadings within the PCs always sums to 1\n",
    "# loadings = pca.components_\n",
    "# num_pc = pca.n_features_\n",
    "# pc_list = [\"PC\"+str(i) for i in list(range(1, num_pc+1))]\n",
    "# loadings_df = pd.DataFrame.from_dict(dict(zip(pc_list, loadings)))\n",
    "# loadings_df['variable'] = df.columns.values\n",
    "# loadings_df = loadings_df.set_index('variable')\n",
    "\n",
    "# # positive and negative values in component loadings reflects the positive and negative correlation of the variables\n",
    "# # with then PCs. \n",
    "\n",
    "# # get correlation matrix plot for loadings\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# ax = sns.heatmap(loadings_df, annot=True, cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA Feature selection, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the new dataset is = (1080, 26)\n"
     ]
    }
   ],
   "source": [
    "#Scale Dataset\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# ANOVA feature selection for numeric input and categorical output\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest, SelectFpr\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "# define feature selection\n",
    "fs = SelectKBest(score_func=f_classif, k=26)\n",
    "# fs = SelectKBest()\n",
    "# fs = SelectFpr(score_func=f_classif, alpha=0.01)\n",
    "# apply feature selection\n",
    "X = fs.fit_transform(X, np.ravel(y))\n",
    "\n",
    "print(\"The shape of the new dataset is = \" + str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_indices = np.arange(X.shape[-1])\n",
    "# selector = SelectKBest(f_classif, k=4)\n",
    "# selector.fit(X, np.ravel(y))\n",
    "# scores = -np.log10(selector.pvalues_)\n",
    "# scores /= scores.max()\n",
    "# plt.bar(X_indices , scores, width=.2,\n",
    "#         label=r'Univariate score ($-Log(p_{value})$)')\n",
    "\n",
    "\n",
    "# plt.title(\"Comparing feature selection\")\n",
    "# plt.xlabel('Feature number')\n",
    "# # plt.yticks(())\n",
    "# plt.axis('tight')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(fs.pvalues_,columns= ['pvalues'],index = features)\n",
    "# df.sort_values(by=['pvalues'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 151461\n",
    "folds = model_selection.ShuffleSplit(n_splits=10, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.828 (+/- 0.031)\n",
      "F1-Score: 0.826 (+/- 0.034)\n",
      "Precision: 0.851 (+/- 0.068)\n",
      "Recall: 0.804 (+/- 0.033)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianProcessClassifier()\n",
    "accuraccy_Gaussian, f1_Gaussian = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, np.ravel(y), random_state=0, test_size =0.20)\n",
    "clf = GaussianProcessClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "plot_confusion_matrix(clf, X_test, y_test)  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.25, max_depth =2, n_estimators=100)\n",
    "accuraccy_GradBoost, f1_GradBoost = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806 (+/- 0.030)\n",
      "F1-Score: 0.809 (+/- 0.029)\n",
      "Precision: 0.815 (+/- 0.065)\n",
      "Recall: 0.805 (+/- 0.063)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=60, kernel = 'poly', degree = 3, gamma = 'scale')\n",
    "accuraccy_SVC, f1_SVC = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845 (+/- 0.039)\n",
      "F1-Score: 0.842 (+/- 0.048)\n",
      "Precision: 0.873 (+/- 0.056)\n",
      "Recall: 0.813 (+/- 0.056)\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 10, p=1, weights='distance')\n",
    "accuraccy_kNN, f1_kNN = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.844 (+/- 0.038)\n",
      "F1-Score: 0.850 (+/- 0.031)\n",
      "Precision: 0.832 (+/- 0.072)\n",
      "Recall: 0.871 (+/- 0.050)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion = 'gini', max_depth = 10, max_features = 'sqrt', min_samples_split = 5, n_estimators = 100)\n",
    "accuraccy_RF, f1_RF = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.849 (+/- 0.038)\n",
      "F1-Score: 0.846 (+/- 0.055)\n",
      "Precision: 0.847 (+/- 0.058)\n",
      "Recall: 0.855 (+/- 0.063)\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation = 'relu', alpha = 0.05, hidden_layer_sizes = (50,100,50), learning_rate = 'adaptive', solver = 'lbfgs')\n",
    "accuraccy_MLP, f1_MLP = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuraccy and F1-score boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.concatenate([np.reshape(accuraccy_Gaussian,(folds.get_n_splits(),1)),\n",
    "                      np.reshape(accuraccy_SVC,(folds.get_n_splits(),1)), \n",
    "                      np.reshape(accuraccy_kNN,(folds.get_n_splits(),1)), \n",
    "                      np.reshape(accuraccy_RF,(folds.get_n_splits(),1)), \n",
    "                      np.reshape(accuraccy_MLP,(folds.get_n_splits(),1))],axis=1)\n",
    "f1 = np.concatenate([np.reshape(f1_Gaussian,(folds.get_n_splits(),1)), \n",
    "                     np.reshape(f1_SVC,(folds.get_n_splits(),1)),\n",
    "                     np.reshape(f1_kNN,(folds.get_n_splits(),1)), \n",
    "                     np.reshape(f1_RF,(folds.get_n_splits(),1)), \n",
    "                     np.reshape(f1_MLP,(folds.get_n_splits(),1))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accdf = pd.DataFrame(acc,columns=['GausProc', 'SVC', 'KNN', 'RandFor', 'MLP'])\n",
    "f1df = pd.DataFrame(f1,columns=['GausProc', 'SVC', 'KNN', 'RandFor', 'MLP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(EO, comparison, accdf, f1df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
