{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'shape' from 'C:\\\\Users\\\\USER\\\\Documents\\\\Yachay_Tech\\\\Thesis_Project\\\\ParkinsonsDetection\\\\python_scripts\\\\shape.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyQt5\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib qt5\n",
    "\n",
    "#python packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pac\n",
    "import warnings\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "import imp\n",
    "import shape\n",
    "import utils\n",
    "from load_features import load_WaveformShape_features, Bandpower_features, mean_and_peak_freqs, statistics, fractal_dimensions, entropies\n",
    "from val_metrics import *\n",
    "\n",
    "imp.reload(utils)\n",
    "imp.reload(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Which comparison to make:\n",
    "    1. Off-med vs Controls\n",
    "    2. On-med vs Controls\n",
    "    3. Off-med vs On-med\n",
    "    \"\"\"\n",
    "comparison = 2\n",
    "dataset = 'UCSD' #UCSD or UNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Which 'comparison' to make:\n",
    "    1. Off-med vs Controls\n",
    "    2. On-med vs Controls\n",
    "    3. Off-med vs On-med\n",
    "    \"\"\"\n",
    "all_chan = True; EO = False\n",
    "bands = [[0.5,4], [4,8], [8,12], [16,32], [32,64]] #Delta, Theta, Alpha, Beta, Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fs, t, S, Sc, Smed, flo, fhi = utils.loadmeta() \n",
    "eeg,rejects = utils.loadPD(EO, all_chan, dataset) # EO means Eyes Opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting a signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a signal\n",
    "sns.set(font_scale=1.2)\n",
    "data = eeg['on'][15]\n",
    "time = np.arange(data.size) / Fs\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.plot(time, data, lw=1.5, color='k')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.xlim([time.min(), time.max()])\n",
    "plt.title('EEG Signal for PD patients on-medication')\n",
    "sns.despine()\n",
    "\n",
    "# plt.plot(eeg['off'][6,0:10],label='control')\n",
    "# plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform Shape Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell saves features from waveform shape and PAC in .pkl files -- Just run once, then commented--\n",
    "\"\"\"\n",
    "\n",
    "# widthS = 3\n",
    "\n",
    "# pks,trs,ShR,PTR,StR,RDR = utils.measure_shape(eeg, rejects, widthS=widthS)\n",
    "\n",
    "\"\"\"\n",
    "Algorithms for estimating phase-amplitude coupling\n",
    "\"\"\"\n",
    "# pac = utils.measure_pac(eeg,rejects,flo,fhi,Fs=Fs)\n",
    "\n",
    "# import pickle\n",
    "# shape_features = [ShR, PTR, StR, RDR, pac]\n",
    "# shape_featuresStr = [\"ShR\", \"PTR\", \"StR\", \"RDR\", \"pac\"]\n",
    "# for i in range(len(shape_features)):\n",
    "#     f = open(shape_featuresStr[i] + \".pkl\",\"wb\")\n",
    "#     pickle.dump(shape_features[i],f)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function calculates the shape measures calculated for analysis\n",
    "    of the PD data set\n",
    "\n",
    "    1. Peak and trough times(pks,trs)\n",
    "    2. Peak and trough sharpness(pksharp,trsharp)\n",
    "    3. Rise and decay steepnes(risteep,desteep)\n",
    "    3. Sharpness ratio(ShR)\n",
    "    4. Steepness ratio(StR)\n",
    "    5. Peak-to-trough ratio(PTR)\n",
    "    6. Rise-to-decay ratio(RDR)\n",
    "    \"\"\"\n",
    "# ShR, PTR, StR, RDR, pac = load_WaveformShape_features(EO, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function calculates the shape measures calculated for analysis\n",
    "    of the PD data set\n",
    "\n",
    "    1. Peak and trough times(pks,trs)\n",
    "    2. Peak and trough sharpness(pksharp,trsharp)\n",
    "    3. Rise and decay steepnes(risteep,desteep)\n",
    "    3. Sharpness ratio(ShR)\n",
    "    4. Steepness ratio(StR)\n",
    "    5. Peak-to-trough ratio(PTR)\n",
    "    6. Rise-to-decay ratio(RDR)\n",
    "    \"\"\"\n",
    "widthS = 3 #To calculate Waveform Shape features\n",
    "\n",
    "pks,trs,ShR,PTR,StR,RDR = utils.measure_shape(eeg, rejects, widthS=widthS)\n",
    "\"\"\"\n",
    "Algorithms for estimating phase-amplitude coupling\n",
    "\"\"\"\n",
    "pac = utils.measure_pac(eeg,rejects,flo,fhi,Fs=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Spectral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Absolute and Relative BandPower features, from all five bands: Delta, Theta, Alpha, Beta, Gamma\n",
    "\"\"\"\n",
    "abs_powerOff = Bandpower_features(eeg['off'], Fs, bands, S, False, 'welch')\n",
    "abs_powerOn = Bandpower_features(eeg['on'], Fs, bands, Smed, False, 'welch')\n",
    "abs_powerCtl = Bandpower_features(eeg['C'], Fs, bands, Sc, False, 'welch')\n",
    "\n",
    "rel_powerOff = Bandpower_features(eeg['off'], Fs, bands, S, True, 'welch')\n",
    "rel_powerOn = Bandpower_features(eeg['on'], Fs, bands, Smed, True, 'welch')\n",
    "rel_powerCtl = Bandpower_features(eeg['C'], Fs, bands, Sc, True, 'welch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mean and Peak Frequency from the spectrum\n",
    "\"\"\"\n",
    "meanFreqsOff = mean_and_peak_freqs(eeg['off'], Fs, S)[0] \n",
    "meanFreqsOn = mean_and_peak_freqs(eeg['on'], Fs, Smed)[0]\n",
    "meanFreqsCtl = mean_and_peak_freqs(eeg['C'], Fs, Sc)[0]\n",
    "\n",
    "peakFreqsOff = mean_and_peak_freqs(eeg['off'], Fs, S)[1]\n",
    "peakFreqsOn = mean_and_peak_freqs(eeg['on'], Fs, Smed)[1]\n",
    "peakFreqsCtl = mean_and_peak_freqs(eeg['C'], Fs, Sc)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell calculates statistical measures extracted from EEG for analysis\n",
    "    of the PD data set\n",
    "\n",
    "    1. Mean\n",
    "    2. Standard Deviation\n",
    "    3. Skewness\n",
    "    4. Kurtosis\n",
    "    5. Maximum\n",
    "    6. Minimum\n",
    "    7. 5th percentile value\n",
    "    8. 25th percentile value\n",
    "    9. 75th percentile value\n",
    "    10. 95th percentile value\n",
    "    11. Median\n",
    "    12. Variance\n",
    "    13. Root Mean Square value\n",
    "    \"\"\"\n",
    "statsOff = statistics(eeg['off'], S).get()\n",
    "statsOn = statistics(eeg['on'], Smed).get()\n",
    "statsCtl = statistics(eeg['C'], Sc).get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractalOff = fractal_dimensions(eeg['off'], S)\n",
    "fractalOn = fractal_dimensions(eeg['on'], Smed)\n",
    "fractalCtl = fractal_dimensions(eeg['C'], Sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "entOff = entropies(eeg['off'], S, Fs)\n",
    "entOn = entropies(eeg['on'], Smed, Fs)\n",
    "entCtl = entropies(eeg['C'], Sc, Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class I\n",
    "f1_B    = np.reshape(pac['off'],(S,1))\n",
    "f2_B    = np.reshape(ShR['off'],(S,1))\n",
    "f3_B    = np.reshape(StR['off'],(S,1))\n",
    "f4_B    = np.reshape(PTR['off'],(S,1))\n",
    "f5_B    = np.reshape(RDR['off'],(S,1))\n",
    "cl_B    = np.ones((S,1)) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class II\n",
    "f1_C    = np.reshape(pac['on'],(Smed,1))\n",
    "f2_C    = np.reshape(ShR['on'],(Smed,1))\n",
    "f3_C    = np.reshape(StR['on'],(Smed,1))\n",
    "f4_C    = np.reshape(PTR['on'],(Smed,1))\n",
    "f5_C    = np.reshape(RDR['on'],(Smed,1))\n",
    "if comparison == 1 or comparison == 3:\n",
    "    cl_C    = np.zeros((Smed,1)) # transition means 0 #Original line\n",
    "elif comparison == 2:\n",
    "    cl_C    = np.ones((Smed,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class III\n",
    "f1_E    = np.reshape(pac['C'],(Sc,1))\n",
    "f2_E    = np.reshape(ShR['C'],(Sc,1))\n",
    "f3_E    = np.reshape(StR['C'],(Sc,1))\n",
    "f4_E    = np.reshape(PTR['C'],(Sc,1))\n",
    "f5_E    = np.reshape(RDR['C'],(Sc,1))\n",
    "cl_E    = np.negative(np.ones((Sc,1))) # -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "MftB = np.concatenate([f1_B,f2_B,f3_B, f4_B, f5_B, rel_powerOff, abs_powerOff, meanFreqsOff, peakFreqsOff, statsOff, fractalOff, entOff, cl_B],axis=1)\n",
    "MftC = np.concatenate([f1_C,f2_C,f3_C, f4_C, f5_C, rel_powerOn,  abs_powerOn,  meanFreqsOn, peakFreqsOn,   statsOn,  fractalOn, entOn,  cl_C],axis=1)\n",
    "MftE = np.concatenate([f1_E,f2_E,f3_E, f4_E, f5_E, rel_powerCtl, abs_powerCtl, meanFreqsCtl, peakFreqsCtl, statsCtl, fractalCtl, entCtl, cl_E],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['PAC','ShR','StR', 'PtT', 'RtF', 'rel_delta',\n",
    "            'rel_theta','rel_alpha','rel_beta',\n",
    "            'rel_gamma','abs_delta','abs_theta',\n",
    "            'abs_alpha','abs_beta','abs_gamma','meanFreq','peakFreq',\n",
    "            'mean','std','skewness', 'kurtosis', 'maximum', 'minimum',\n",
    "            '5th perc','25th perc','75th perc','95th perc','median','variance','RMS',\n",
    "           'detrended_fluctuation', 'higuchi_fd', 'katz_fd', 'petrosian_fd',\n",
    "           'perm_entropy', 'svd_entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCM_B = pd.DataFrame(MftB,columns= features + ['class'])\n",
    "FCM_C = pd.DataFrame(MftC,columns= features + ['class'])\n",
    "FCM_E = pd.DataFrame(MftE,columns= features + ['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification between patients on-medication and patients off-medication   \n",
    "\n",
    "if comparison == 3:\n",
    "    TotalDataset = pd.concat([FCM_B,FCM_C],ignore_index=True)\n",
    "    visDat = TotalDataset.copy(deep=True)\n",
    "    visDat['class'] = visDat['class'].map({1:'off_med',0:'on_med'})\n",
    "\n",
    "#Classification between patients on-medication and healthy control subjects        \n",
    "\n",
    "elif comparison == 2:\n",
    "    TotalDataset = pd.concat([FCM_C,FCM_E],ignore_index=True)\n",
    "    visDat = TotalDataset.copy(deep=True)\n",
    "    # visDat['class'] = visDat['class'].map({-1:'control',0:'on_med'}) #Original line\n",
    "    visDat['class'] = visDat['class'].map({-1:'control',1:'on_med'})\n",
    "\n",
    "#Classification between patients off-medication and healthy control subjects        \n",
    "\n",
    "elif comparison == 1:\n",
    "    TotalDataset = pd.concat([FCM_E,FCM_B],ignore_index=True)\n",
    "    visDat = TotalDataset.copy(deep=True)\n",
    "    visDat['class'] = visDat['class'].map({-1:'control',1:'off_med'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAC</th>\n",
       "      <th>ShR</th>\n",
       "      <th>StR</th>\n",
       "      <th>PtT</th>\n",
       "      <th>RtF</th>\n",
       "      <th>rel_delta</th>\n",
       "      <th>rel_theta</th>\n",
       "      <th>rel_alpha</th>\n",
       "      <th>rel_beta</th>\n",
       "      <th>rel_gamma</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>variance</th>\n",
       "      <th>RMS</th>\n",
       "      <th>detrended_fluctuation</th>\n",
       "      <th>higuchi_fd</th>\n",
       "      <th>katz_fd</th>\n",
       "      <th>petrosian_fd</th>\n",
       "      <th>perm_entropy</th>\n",
       "      <th>svd_entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.965826</td>\n",
       "      <td>1.018334</td>\n",
       "      <td>0.160536</td>\n",
       "      <td>0.188544</td>\n",
       "      <td>0.215391</td>\n",
       "      <td>0.290536</td>\n",
       "      <td>0.105444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147196</td>\n",
       "      <td>44.335599</td>\n",
       "      <td>5.200195</td>\n",
       "      <td>0.694626</td>\n",
       "      <td>1.329258</td>\n",
       "      <td>3.614550</td>\n",
       "      <td>1.010760</td>\n",
       "      <td>2.233689</td>\n",
       "      <td>0.900570</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048979</td>\n",
       "      <td>0.081868</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.828194</td>\n",
       "      <td>1.007320</td>\n",
       "      <td>0.093071</td>\n",
       "      <td>0.121841</td>\n",
       "      <td>0.080416</td>\n",
       "      <td>0.206895</td>\n",
       "      <td>0.325862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184526</td>\n",
       "      <td>137.111610</td>\n",
       "      <td>9.178630</td>\n",
       "      <td>0.660148</td>\n",
       "      <td>1.699939</td>\n",
       "      <td>4.506174</td>\n",
       "      <td>1.011811</td>\n",
       "      <td>2.305504</td>\n",
       "      <td>1.285569</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>1.024380</td>\n",
       "      <td>1.117357</td>\n",
       "      <td>0.315638</td>\n",
       "      <td>0.177761</td>\n",
       "      <td>0.159741</td>\n",
       "      <td>0.207027</td>\n",
       "      <td>0.225231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083672</td>\n",
       "      <td>13.698079</td>\n",
       "      <td>2.873184</td>\n",
       "      <td>0.794236</td>\n",
       "      <td>1.627005</td>\n",
       "      <td>3.901378</td>\n",
       "      <td>1.012982</td>\n",
       "      <td>2.362892</td>\n",
       "      <td>1.136908</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.045132</td>\n",
       "      <td>0.026650</td>\n",
       "      <td>0.901297</td>\n",
       "      <td>1.063287</td>\n",
       "      <td>0.125193</td>\n",
       "      <td>0.065370</td>\n",
       "      <td>0.082224</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.265845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084805</td>\n",
       "      <td>64.883761</td>\n",
       "      <td>6.245067</td>\n",
       "      <td>0.665163</td>\n",
       "      <td>1.792458</td>\n",
       "      <td>4.740969</td>\n",
       "      <td>1.013654</td>\n",
       "      <td>2.422854</td>\n",
       "      <td>1.385232</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015581</td>\n",
       "      <td>0.025718</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.942502</td>\n",
       "      <td>1.019449</td>\n",
       "      <td>0.167847</td>\n",
       "      <td>0.092750</td>\n",
       "      <td>0.104343</td>\n",
       "      <td>0.220804</td>\n",
       "      <td>0.311636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313019</td>\n",
       "      <td>29.723154</td>\n",
       "      <td>4.262029</td>\n",
       "      <td>0.756551</td>\n",
       "      <td>1.664885</td>\n",
       "      <td>4.312527</td>\n",
       "      <td>1.012126</td>\n",
       "      <td>2.317893</td>\n",
       "      <td>1.228517</td>\n",
       "      <td>off_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.054289</td>\n",
       "      <td>0.035911</td>\n",
       "      <td>0.094564</td>\n",
       "      <td>1.086204</td>\n",
       "      <td>0.804333</td>\n",
       "      <td>0.137295</td>\n",
       "      <td>0.217630</td>\n",
       "      <td>0.206912</td>\n",
       "      <td>0.179459</td>\n",
       "      <td>0.206942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023963</td>\n",
       "      <td>43.464109</td>\n",
       "      <td>5.143440</td>\n",
       "      <td>0.640378</td>\n",
       "      <td>1.611932</td>\n",
       "      <td>4.277311</td>\n",
       "      <td>1.012396</td>\n",
       "      <td>2.334022</td>\n",
       "      <td>1.180773</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0.026948</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>1.129353</td>\n",
       "      <td>0.765503</td>\n",
       "      <td>0.257445</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.185560</td>\n",
       "      <td>0.227640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>24.561608</td>\n",
       "      <td>3.877497</td>\n",
       "      <td>0.716123</td>\n",
       "      <td>1.720568</td>\n",
       "      <td>4.457114</td>\n",
       "      <td>1.013577</td>\n",
       "      <td>2.398445</td>\n",
       "      <td>1.295304</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0.065171</td>\n",
       "      <td>0.023796</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>1.056320</td>\n",
       "      <td>0.755698</td>\n",
       "      <td>0.142134</td>\n",
       "      <td>0.245133</td>\n",
       "      <td>0.243544</td>\n",
       "      <td>0.176670</td>\n",
       "      <td>0.192061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173929</td>\n",
       "      <td>84.545968</td>\n",
       "      <td>7.233617</td>\n",
       "      <td>0.666495</td>\n",
       "      <td>1.540297</td>\n",
       "      <td>3.980859</td>\n",
       "      <td>1.012198</td>\n",
       "      <td>2.324535</td>\n",
       "      <td>1.138620</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.032679</td>\n",
       "      <td>0.098393</td>\n",
       "      <td>1.078151</td>\n",
       "      <td>0.797273</td>\n",
       "      <td>0.192164</td>\n",
       "      <td>0.089684</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>0.130481</td>\n",
       "      <td>0.292350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>130.151138</td>\n",
       "      <td>7.674405</td>\n",
       "      <td>0.479596</td>\n",
       "      <td>1.724914</td>\n",
       "      <td>3.362345</td>\n",
       "      <td>1.011705</td>\n",
       "      <td>2.315616</td>\n",
       "      <td>1.371452</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.017394</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>0.033053</td>\n",
       "      <td>0.972561</td>\n",
       "      <td>0.926717</td>\n",
       "      <td>0.320450</td>\n",
       "      <td>0.162669</td>\n",
       "      <td>0.137617</td>\n",
       "      <td>0.193584</td>\n",
       "      <td>0.268039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031786</td>\n",
       "      <td>24.566163</td>\n",
       "      <td>3.911432</td>\n",
       "      <td>0.771297</td>\n",
       "      <td>1.648602</td>\n",
       "      <td>4.427453</td>\n",
       "      <td>1.011919</td>\n",
       "      <td>2.305304</td>\n",
       "      <td>1.131057</td>\n",
       "      <td>on_med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PAC       ShR       StR       PtT       RtF  rel_delta  rel_theta  \\\n",
       "0    0.004507  0.015101  0.007890  0.965826  1.018334   0.160536   0.188544   \n",
       "1    0.048979  0.081868  0.003167  0.828194  1.007320   0.093071   0.121841   \n",
       "2    0.009106  0.010461  0.048192  1.024380  1.117357   0.315638   0.177761   \n",
       "3    0.033689  0.045132  0.026650  0.901297  1.063287   0.125193   0.065370   \n",
       "4    0.015581  0.025718  0.008366  0.942502  1.019449   0.167847   0.092750   \n",
       "..        ...       ...       ...       ...       ...        ...        ...   \n",
       "932  0.054289  0.035911  0.094564  1.086204  0.804333   0.137295   0.217630   \n",
       "933  0.026948  0.052830  0.116053  1.129353  0.765503   0.257445   0.165237   \n",
       "934  0.065171  0.023796  0.121652  1.056320  0.755698   0.142134   0.245133   \n",
       "935  0.034843  0.032679  0.098393  1.078151  0.797273   0.192164   0.089684   \n",
       "936  0.017394  0.012083  0.033053  0.972561  0.926717   0.320450   0.162669   \n",
       "\n",
       "     rel_alpha  rel_beta  rel_gamma  ...    median    variance       RMS  \\\n",
       "0     0.215391  0.290536   0.105444  ... -0.147196   44.335599  5.200195   \n",
       "1     0.080416  0.206895   0.325862  ... -0.184526  137.111610  9.178630   \n",
       "2     0.159741  0.207027   0.225231  ... -0.083672   13.698079  2.873184   \n",
       "3     0.082224  0.168007   0.265845  ...  0.084805   64.883761  6.245067   \n",
       "4     0.104343  0.220804   0.311636  ... -0.313019   29.723154  4.262029   \n",
       "..         ...       ...        ...  ...       ...         ...       ...   \n",
       "932   0.206912  0.179459   0.206942  ... -0.023963   43.464109  5.143440   \n",
       "933   0.115304  0.185560   0.227640  ...  0.028889   24.561608  3.877497   \n",
       "934   0.243544  0.176670   0.192061  ...  0.173929   84.545968  7.233617   \n",
       "935   0.069790  0.130481   0.292350  ...  0.029313  130.151138  7.674405   \n",
       "936   0.137617  0.193584   0.268039  ... -0.031786   24.566163  3.911432   \n",
       "\n",
       "     detrended_fluctuation  higuchi_fd   katz_fd  petrosian_fd  perm_entropy  \\\n",
       "0                 0.694626    1.329258  3.614550      1.010760      2.233689   \n",
       "1                 0.660148    1.699939  4.506174      1.011811      2.305504   \n",
       "2                 0.794236    1.627005  3.901378      1.012982      2.362892   \n",
       "3                 0.665163    1.792458  4.740969      1.013654      2.422854   \n",
       "4                 0.756551    1.664885  4.312527      1.012126      2.317893   \n",
       "..                     ...         ...       ...           ...           ...   \n",
       "932               0.640378    1.611932  4.277311      1.012396      2.334022   \n",
       "933               0.716123    1.720568  4.457114      1.013577      2.398445   \n",
       "934               0.666495    1.540297  3.980859      1.012198      2.324535   \n",
       "935               0.479596    1.724914  3.362345      1.011705      2.315616   \n",
       "936               0.771297    1.648602  4.427453      1.011919      2.305304   \n",
       "\n",
       "     svd_entropy    class  \n",
       "0       0.900570  off_med  \n",
       "1       1.285569  off_med  \n",
       "2       1.136908  off_med  \n",
       "3       1.385232  off_med  \n",
       "4       1.228517  off_med  \n",
       "..           ...      ...  \n",
       "932     1.180773   on_med  \n",
       "933     1.295304   on_med  \n",
       "934     1.138620   on_med  \n",
       "935     1.371452   on_med  \n",
       "936     1.131057   on_med  \n",
       "\n",
       "[937 rows x 37 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visDat.head(3240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = np.arange(0,1)\n",
    "off = FCM_B.iloc[:,interval].mean(axis=0)\n",
    "on = FCM_C.iloc[:,interval].mean(axis=0)\n",
    "control = FCM_E.iloc[:,interval].mean(axis=0)\n",
    "\n",
    "df = pd.DataFrame({'PD Off-medication': off,\n",
    "                   'PD On-medication': on,\n",
    "                   'Healthy': control}, index=np.asarray(features)[interval])\n",
    "ax = df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TotalDataset[features]#.iloc[:,5:10]\n",
    "y = TotalDataset[['class']]\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn import datasets\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # load dataset\n",
    "# df = pd.DataFrame(X, columns=features)\n",
    "\n",
    "# # Standarize Data\n",
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(df)\n",
    "# data_scaled = pd.DataFrame(scaler.transform(df),columns = df.columns) \n",
    "\n",
    "# # PCA\n",
    "# pca = PCA(.95)\n",
    "# # pca.fit_transform(data_scaled)\n",
    "# X = pca.fit_transform(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get component loadings (correlation coefficient between original variables and the component) \n",
    "# # the squared loadings within the PCs always sums to 1\n",
    "# loadings = pca.components_\n",
    "# num_pc = pca.n_features_\n",
    "# pc_list = [\"PC\"+str(i) for i in list(range(1, num_pc+1))]\n",
    "# loadings_df = pd.DataFrame.from_dict(dict(zip(pc_list, loadings)))\n",
    "# loadings_df['variable'] = df.columns.values\n",
    "# loadings_df = loadings_df.set_index('variable')\n",
    "\n",
    "# # positive and negative values in component loadings reflects the positive and negative correlation of the variables\n",
    "# # with then PCs. \n",
    "\n",
    "# # get correlation matrix plot for loadings\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# ax = sns.heatmap(loadings_df, annot=True, cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA Feature selection, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the new dataset is = (937, 20)\n"
     ]
    }
   ],
   "source": [
    "#Scale Dataset\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# ANOVA feature selection for numeric input and categorical output\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest, SelectFpr\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "# define feature selection\n",
    "fs = SelectKBest(score_func=f_classif, k=20)\n",
    "# fs = SelectKBest()\n",
    "# fs = SelectFpr(score_func=f_classif, alpha=0.01)\n",
    "# apply feature selection\n",
    "X = fs.fit_transform(X, np.ravel(y))\n",
    "\n",
    "print(\"The shape of the new dataset is = \" + str(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_indices = np.arange(X.shape[-1])\n",
    "selector = SelectKBest(f_classif, k=4)\n",
    "selector.fit(X, np.ravel(y))\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()\n",
    "plt.bar(X_indices , scores, width=.2,\n",
    "        label=r'Univariate score ($-Log(p_{value})$)')\n",
    "\n",
    "\n",
    "plt.title(\"Comparing feature selection\")\n",
    "plt.xlabel('Feature number')\n",
    "# plt.yticks(())\n",
    "plt.axis('tight')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(fs.pvalues_,columns= ['pvalues'],index = features)\n",
    "# df.sort_values(by=['pvalues'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Sklearn libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 151461\n",
    "folds = model_selection.ShuffleSplit(n_splits=10, test_size=0.10, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.717 (+/- 0.053)\n",
      "F1-Score: 0.719 (+/- 0.052)\n",
      "Precision: 0.702 (+/- 0.083)\n",
      "Recall: 0.742 (+/- 0.106)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianProcessClassifier()\n",
    "accuraccy_Gaussian, f1_Gaussian = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.25, max_depth =2, n_estimators=100)\n",
    "accuraccy_GradBoost, f1_GradBoost = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.720 (+/- 0.093)\n",
      "F1-Score: 0.724 (+/- 0.080)\n",
      "Precision: 0.703 (+/- 0.066)\n",
      "Recall: 0.748 (+/- 0.123)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=80, kernel = 'rbf', degree = 5, gamma = 'auto')\n",
    "accuraccy_SVC, f1_SVC = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.726 (+/- 0.091)\n",
      "F1-Score: 0.726 (+/- 0.102)\n",
      "Precision: 0.707 (+/- 0.076)\n",
      "Recall: 0.747 (+/- 0.145)\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 4, p=2, weights='distance')\n",
    "accuraccy_kNN, f1_kNN = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.753 (+/- 0.074)\n",
      "F1-Score: 0.757 (+/- 0.070)\n",
      "Precision: 0.723 (+/- 0.077)\n",
      "Recall: 0.804 (+/- 0.113)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion = 'entropy', max_depth = None,\n",
    "                             max_features = 'log2', min_samples_split = 2, \n",
    "                             n_estimators = 350)\n",
    "accuraccy_RF, f1_RF = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.738 (+/- 0.086)\n",
      "F1-Score: 0.752 (+/- 0.075)\n",
      "Precision: 0.746 (+/- 0.102)\n",
      "Recall: 0.740 (+/- 0.082)\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation = 'relu', alpha = 0.0001, \n",
    "                    hidden_layer_sizes = (50,50,50), \n",
    "                    learning_rate = 'constant', solver = 'lbfgs')\n",
    "accuraccy_MLP, f1_MLP = cross_vald(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(clf, folds, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuraccy and F1-score boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.concatenate([np.reshape(accuraccy_Gaussian,(folds.get_n_splits(),1)),\n",
    "                      np.reshape(accuraccy_SVC,(folds.get_n_splits(),1)), \n",
    "                      np.reshape(accuraccy_kNN,(folds.get_n_splits(),1)), \n",
    "                      np.reshape(accuraccy_RF,(folds.get_n_splits(),1)), \n",
    "                      np.reshape(accuraccy_MLP,(folds.get_n_splits(),1))],axis=1)\n",
    "f1 = np.concatenate([np.reshape(f1_Gaussian,(folds.get_n_splits(),1)), \n",
    "                     np.reshape(f1_SVC,(folds.get_n_splits(),1)),\n",
    "                     np.reshape(f1_kNN,(folds.get_n_splits(),1)), \n",
    "                     np.reshape(f1_RF,(folds.get_n_splits(),1)), \n",
    "                     np.reshape(f1_MLP,(folds.get_n_splits(),1))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "accdf = pd.DataFrame(acc,columns=['GausProc', 'SVC', 'KNN', 'RandFor', 'MLP'])\n",
    "f1df = pd.DataFrame(f1,columns=['GausProc', 'SVC', 'KNN', 'RandFor', 'MLP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(EO, comparison, accdf, f1df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
